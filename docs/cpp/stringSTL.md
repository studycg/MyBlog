# String类

C++11之后的string拷贝都是直接深拷贝的

## SSO机制

**SSO (小字符串优化)** 现代编译器（GCC, Clang, MSVC）的 `string` 类内部其实是一个 **Union（联合体）**。

~~~c++
class string {
    char* ptr;       // 指向数据的指针 (8字节)
    size_t size;     // 当前长度 (8字节)
    union {
        size_t capacity; // 容量 (8字节) - 用于长字符串
        char buffer[16]; // 本地缓存 (16字节) - 用于短字符串
    };
};
~~~

**短模式 (Short Mode)**：

- 如果你存 "Hello"（5字节），它**不申请堆内存**！
- 它直接把数据存进对象内部的 `buffer` 数组里（栈上）。
- **没有 `new`，没有 `delete`，速度极快。**

**长模式 (Long Mode)**：

- 如果你存一篇作文。
- `buffer` 存不下。它会去堆上 `new` 内存，`ptr` 指向堆，`capacity` 记录容量。

在设计数据结构时，尽量控制字符串长度。如果能控制在 15 或 22 字节以内（取决于编译器实现），就能触发 SSO，性能会有质的飞跃。

### `size()`与`capacity()`区别

这是 `string` 和 `vector` 共有的一套逻辑。

- **`size()` 或 `length()`**：实际字符的个数。
- **`capacity()`**：当前分配的内存能装多少字符（不需要重新分配）。

~~~c++
string s = "";
for (int i = 0; i < 10000; ++i) {
    s += "x"; // 灾难！
}
~~~

当 `size` 超过 `capacity` 时，`string` 会：

1. `malloc` 一块更大的新内存（通常是 1.5 倍或 2 倍）。
2. 把旧数据搬过去。
3. `free` 旧内存。

- 在这个循环里，可能会发生几十次内存搬迁，极慢。

## 预分配

~~~c++
string s;
s.reserve(10000); // 提前告诉它：给我准备好 10000 的空间
// 此时 capacity = 10000, size = 0
// 接下来的 10000 次 += 操作，0 次内存分配。
~~~

## C++17:std::string_view

~~~c++
void func(const std::string& s) { ... }

func("hello world");
~~~

虽然传参是引用，但在调用前，编译器必须把 C 风格字符串 `"hello world"` **转换成** 一个临时的 `std::string` 对象（发生一次 `malloc` 和拷贝），然后再传进去。这依然有开销。

**`std::string_view`** 它只是一个**“窗口”**，只包含两个简单的成员：

1. `const char* ptr` (指向字符串开头)
2. `size_t size` (长度)

它**不拥有**内存，只**借看**内存。

~~~c++
#include <string_view>

void func(std::string_view sv) { // 按值传递即可（因为它极小，就两个整数大）
    // 可以像 string 一样用，但不能修改内容
    cout << sv.substr(0, 5); 
}

func("hello world"); // ✅ 零拷贝！没有 new，没有 string 对象生成。
~~~

# 智能指针

## unique_ptr

**独占所有权**：同一时间，只能有一个 `unique_ptr` 拥有这块内存。

**禁止拷贝**：它删除了拷贝构造函数和赋值运算符（`= delete`）。

~~~c++
unique_ptr<int> p1(new int(10));
unique_ptr<int> p2 = p1; // ❌ 编译报错！禁止拷贝
~~~

**支持移动**：如果你想转移所有权，必须显式使用 `std::move`。

~~~c++
unique_ptr<int> p2 = std::move(p1); // ✅ 合法。p1 变空，p2 接管。
~~~

`unique_ptr` 在默认情况下，**大小和裸指针完全一样**（64位系统下是 8 字节）。 它没有任何额外的控制块，也没有引用计数。 **结论**：使用 `unique_ptr` 和使用裸指针相比，**没有任何性能损耗**，只有安全保障。

~~~c++
// 不推荐：
unique_ptr<Hero> p(new Hero("Cloud"));
// 推荐：
auto p = std::make_unique<Hero>("Cloud");
~~~

除了写起来短，还能避免一种极罕见的因参数求值顺序导致的内存泄漏。

**栈帧绑定（RAII）**： `unique_ptr` 本身通常是一个**栈对象**。

- 当函数结束，栈帧弹出，`unique_ptr` 必然析构。
- 它的析构函数里写死了 `delete ptr;`。
- 因为编译器保证了它是独占的，绝对安全，不会发生Double Free。

## 引用计数与shared_ptr

当你需要**“多个对象同时拥有同一个资源”**时使用。比如一个 `Room` 对象被多个 `Player` 对象持有。

**引用计数**

每多一个 `shared_ptr` 指向它，计数 +1；每销毁一个，计数 -1。当计数归零时，`delete` 资源。

 **内存布局**

这是 **“双指针”** 结构。 一个 `shared_ptr` 对象本身占用 **16 字节**（是裸指针的两倍）：

1. **Raw Pointer**：指向实际的数据对象（为了快速解引用）。
2. **Control Block Pointer**：指向堆上的 **控制块 (Control Block)**。

**控制块里有什么？**

- **Strong Count**：强引用计数（多少 `shared_ptr` 活着）。
- **Weak Count**：弱引用计数（多少 `weak_ptr` 活着）。
- **Deleter**：自定义删除器（比如 `fclose` 而不是 `delete`）。
- **Allocator**：分配器。

**原子操作**：引用计数的加减必须是**线程安全**的。这比普通的 `++` 慢很多。

**内存碎片**：

- `shared_ptr<int> p(new int(10));`
- 这里发生了**两次**堆分配：一次是 `new int`，一次是为 `Control Block` 分配。
- **优化**：使用 **`std::make_shared`**。它会把数据对象和控制块合并成**一次**大内存分配。

## weak_ptr

**只引用、不计数**

循环引用情况：

Parent 存了一个 `shared_ptr<Child>`。

Child 存了一个 `shared_ptr<Parent>`。

~~~c++
parent->child = child;
child->parent = parent;
~~~

Parent 的计数是 1（被 Child 持有），Child 的计数是 1（被 Parent 持有）。 当 `main` 函数结束时，外部的指针销毁了，但它们内部互相抓着对方。**计数永远无法归零，内存永远无法释放。**

把其中一方（通常是 Child 指向 Parent 的那根线）改为 `weak_ptr`。

- `weak_ptr` **不增加引用计数**。
- 当 Parent 外部计数归零时，Parent 就会析构（不管 Child 里的 weak_ptr 还指没指着它）。
- Parent 析构了，它持有的 `shared_ptr<Child>` 也就释放了，Child 的计数归零，Child 也析构了。**完美解开死锁。**

`weak_ptr` 不能直接访问对象（因为它指向的对象可能已经死了）。 必须先调用 `lock()` 把它升级为 `shared_ptr`。


~~~
std::weak_ptr<Parent> wp = parent;
// ...
if (auto sp = wp.lock()) { // 检查对象还在不在
    sp->doSomething(); // 还在，安全使用
} else {
    // 对象已经没了
}
~~~

| **指针类型**   | **关键特性**           | **适用场景**                                | **内存开销**           |
| -------------- | ---------------------- | ------------------------------------------- | ---------------------- |
| **unique_ptr** | 独占、不可拷贝、可移动 | **默认首选**。工厂函数返回、类成员变量。    | 极低 (同裸指针)        |
| **shared_ptr** | 共享、引用计数         | 多对一关系、像 Python/Java 那样的对象管理。 | 中 (双倍指针 + 控制块) |
| **weak_ptr**   | 不计数、防循环引用     | 解决 `shared_ptr` 循环引用、缓存系统。      | 中 (配合 shared_ptr)   |
| **auto_ptr**   | ❌ 缺陷设计             | **垃圾桶**。别用。                          | -                      |

## weak_ptr::lock()

`weak_ptr` 虽然不持有对象，但它持有指向 **控制块 (Control Block)** 的指针。即使对象没了，控制块还在（只要 Weak Count > 0）。

**lock() 的步骤：**

1. **访问控制块**：`weak_ptr` 通过内部指针找到堆上的控制块。
2. **检查强引用**：读取控制块里的 **强引用计数**。
3. **原子升级（CAS 操作）**：
   - 如果 Strong Count == 0：说明对象已经挂了。返回空的 `shared_ptr`。
   - 如果 Strong Count > 0： 这里必须非常小心！在多线程环境下，可能你刚读到 > 0，另一个线程就把对象释放了。 所以，标准库通常使用 **原子操作 (Atomic Compare-and-Swap / Fetch-Add)**。
     - 它尝试将 Strong Count 加 1。
     - 如果加成功了，说明对象被我“锁住”了，不能被释放。
     - 然后利用这个已经 +1 的计数，构造一个新的 `shared_ptr` 返回。

## 关于双分配

`shared_ptr<int> p(new int(10))`的双重分配

过程是这样的：

1. **用户代码**：执行 `new int(10)`。

   - 操作系统在堆上分配了 4 字节（假设 int 为 4 字节）。
   - **结果**：产生了一个裸指针 `raw_ptr`。
2.  **构造函数**：调用 `shared_ptr` 的构造函数，传入 `raw_ptr`。

   - `shared_ptr` 发现需要管理这个指针，但它还需要一个地方存引用计数。
   - 于是，`shared_ptr` 内部再次向堆申请一块内存，用来创建 **控制块**。

3. **最终状态**：
   - 堆上有两块**不连续**的内存：一块是数据 `int(10)`，一块是控制块。
   - `shared_ptr` 内部持有两个指针，分别指向它们。

发生了**两次**堆内存分配（两次 `malloc`/`new`）。这不仅慢，而且因为内存不连续，会降低 CPU 的缓存命中率。

## std::make_shared

`std::make_shared` 的核心在于**“一次分配，整块打包”**。

过程是这样的：

1. `make_shared` 计算出大小：`sizeof(int) + sizeof(Control Block)`。
2. 它只调用**一次**内存分配函数，申请一大块连续内存。
3. 在这块大内存的**前半部分**（通常），它构造控制块。
4. 在这块大内存的**后半部分**，它使用 **Placement New**（定位构造）技术，直接在原位构造 `int(10)` 对象。

**性能提升**：只有一次 `malloc` 开销。

**缓存友好**：控制块和数据紧挨在一起，CPU 加载控制块时，很可能顺便把数据也加载进缓存行（Cache Line）了。

**异常安全**：防止了“`new int` 成功但分配控制块失败”导致的内存泄漏风险。

**但是也有不好的地方**：因为控制块和对象在同一块内存里，只要控制块还活着（还有 `weak_ptr` 引用它），这**整块**大内存（包括数据占用的那部分）都无法释放给操作系统。即使强引用计数归零，对象析构了，但这块内存还得留着给 `weak_ptr` 用来查数。如果对象很大（比如 100MB），这会延迟内存回收。

## 傻逼写法

~~~c++
// ❌ 极度不推荐
std::unique_ptr<int>* p = new std::unique_ptr<int>(new int(10));
//                        ↑ 第一次new               ↑ 第二次new
~~~

~~~c++
p (栈上) → 堆内存地址 → 包含一个 unique_ptr 对象
                    这个 unique_ptr 对象又管理着另一个堆上的 int(10)
~~~

~~~c++
栈内存：
┌─────────────┐
│ 指针 p      │──┐
│ (8字节)     │  │
└─────────────┘  │
                 ↓
第一次堆分配：     ↓
┌─────────────┐  │
│ unique_ptr  │←─┘
│ 对象本身     │
│ (通常8字节)  │
│ 包含一个指针 →→┐
└─────────────┘  │
                 ↓
第二次堆分配：     ↓
┌─────────────┐  │
│ int(10)     │←─┘
│ (4字节)     │
└─────────────┘
~~~

~~~c++
// 即使是这种设计，也应该这样写：
auto p = std::make_unique<std::unique_ptr<int>>(std::make_unique<int>(10));
// 两次堆分配，但全部自动管理
~~~

## 智能指针在栈上

~~~c++
void func() {
    // 1. ptr 对象本身（那个“壳”）在栈上
    // 2. new int(10) 的数据在堆上
    std::unique_ptr<int> ptr = std::make_unique<int>(10);
    
    // ... 函数结束
} // ptr 离开栈作用域，自动析构 -> 触发 delete -> 释放堆上的 int
~~~

**栈 (Stack)**：存放 `ptr` 这个变量。

- 对于 `unique_ptr`，它只占 8 字节（一个裸指针的大小）。
- 对于 `shared_ptr`，它占 16 字节（两个指针的大小）。

**堆 (Heap)**：存放那个 `int(10)` 数据（以及 `shared_ptr` 的控制块）。

**关系**：**栈上的壳，指着堆上的肉。**

正是因为 `ptr` 对象在栈上，当函数 `func` 结束时，**栈解退 (Stack Unwinding)** 机制才会自动调用 `ptr` 的析构函数。如果 `ptr` 不在栈上，谁来触发它的析构呢？这就是 RAII 的核心。

### 若智能指针作为成员变量则跟随宿主

~~~c++
class Hero {
public:
    std::unique_ptr<Weapon> weapon; // 成员变量
};

void game() {
    // 情况 A：Hero 在栈上
    Hero h; 
    // -> h 在栈上，h.weapon 这个智能指针对象也在栈上。
    // -> h.weapon 指向的 Weapon 数据在堆上。

    // 情况 B：Hero 在堆上
    Hero* ph = new Hero(); 
    // -> ph 指向的 Hero 对象在堆上。
    // -> 也就是 h->weapon 这个智能指针对象本身存储在堆上（作为 Hero 的一部分）。
    // -> h->weapon 指向的 Weapon 数据在另一块堆内存上。
}
~~~

## 智能指针与内存泄漏

假设有一个函数 `process`，它接受两个参数：

1. 一个 `unique_ptr<Hero>`。
2. 一个普通函数的返回值（这个函数可能会抛出异常）。

```c++
void process(std::unique_ptr<Hero> p, int priority);

int getPriority() {
    throw "Error!"; // 假设这个函数不幸抛出了异常
    return 10;
}

// ❌ 危险写法
process(std::unique_ptr<Hero>(new Hero("Cloud")), getPriority());
```

在 C++17 之前，标准**没有规定**函数参数的计算顺序。编译器可以按照它认为最优的顺序来执行这三个步骤：

1. **Step A**: 执行 `new Hero("Cloud")`。 -> **堆内存申请成功，返回裸指针 ptr**。
2. **Step B**: 执行 `std::unique_ptr` 的构造函数（把 ptr 包装起来）。
3. **Step C**: 执行 `getPriority()`。

如果编译器决定把顺序打乱，变成这样（这是允许的）：

1. **Step A**: 执行 `new Hero("Cloud")`。 -> **拿到裸指针 ptr**。
2. **Step C**: 执行 `getPriority()`。 -> **💥 抛出异常！**
3. **Step B**: （因为异常，这步永远不会执行了！）`unique_ptr` 的构造函数没跑。

**后果**： 第一步申请出来的 `ptr` 悬在半空。因为 `unique_ptr` 还没来得及由构造函数接管它（Step B 没跑），所以没有任何人负责 `delete` 它。 **结论**：**Hero 对象发生了内存泄漏。**

~~~c++
// ✅ 安全写法
process(std::make_unique<Hero>("Cloud"), getPriority());
~~~

`std::make_unique` 是一个函数调用。

 **C++ 保证：在一个函数调用完成之前，它内部的步骤必须全部完成。**

也就是说，`make_unique` 内部的 `new` 和 `unique_ptr` 的构造是**原子绑定**在一起的。

只有两种可能的顺序：

1. 先完整跑完 `make_unique`（申请内存+构造指针），再跑 `getPriority()`。
   - 如果 `getPriority` 挂了，`unique_ptr` 已经生成了，作为临时对象，栈解退时会自动析构 `Hero`。**安全。**
2. 先跑 `Priority()`，再跑 `make_unique`。
   - 如果 `getPriority` 挂了，`make_unique` 还没跑，内存还没申请。**安全。**

**好 那我们接下来攻关STL**？？GEMINI搜索到这里

# 序列容器

## vector

### vector的结构

`vector` 对象本身（存储在栈上的那部分）非常小，在 64 位系统下通常只占 **24 字节**。为什么是 24 字节？因为它内部维护了 **三个指针**（这是 GCC/Clang 的经典实现）：

1. **`_Myfirst` (start)**: 指向堆内存中连续空间的**起始位置**。
2. **`_Mylast` (finish)**: 指向**最后一个有效元素之后**的位置（即 `size()` 的边界）。
3. **`_Myend` (end_of_storage)**: 指向**整块已分配内存的末尾**（即 `capacity()` 的边界）。

**隐藏的计算公式**

基于这三个指针，`vector` 所有的操作都可以迅速计算出来：

- **`size()`** = `_Mylast - _Myfirst`
- **`capacity()`** = `_Myend - _Myfirst`
- **`empty()`** = `_Mylast == _Myfirst`
- **`operator[] (i)`** = `*(_Myfirst + i)`
- **`end()`** = `_Mylast`

### **扩容机制**

这是 `vector` 最复杂、最昂贵的操作。当用户调用 `push_back` 但 `size() == capacity()` 时，就会触发扩容。

扩容过程：

1. 分配: 计算新容量（通常是旧容量的 2倍 或 1.5倍），在堆上寻找一块新的、更大的连续内存。
2. 迁移: 将旧内存里的元素拷贝（Copy）或者移动（Move）到新内存中。
   - *注意：C++11 之前是拷贝，效率低；C++11 后如果对象有 `noexcept` 的移动构造函数，则是移动，效率极高。*
   - 不论是拷贝还是移动时间复杂度都是O(n)，但是移动单步时间更快。
3. 析构: 调用旧内存中所有对象的析构函数。
4. 释放: 归还旧的那块堆内存给操作系统。
5. 更新指针: 把 `_Myfirst` 等三个指针指向新家。

**扩容的时间复杂度是摊销的为常数的**

既然扩容这么慢（$O(N)$），为什么说 push_back 是 $O(1)$ 的？

因为扩容发生的频率极低。

- 第 1 次扩容拷贝 1 个。
- 第 2 次扩容拷贝 2 个。
- 第 4 次扩容拷贝 4 个...
- 平均分摊到每一次 `push_back` 上，成本就是一个常数。这叫摊销常数时间。

**2倍扩容和1.5倍扩容的策略**

不同的编译器策略不同（MSVC 用 1.5 倍，GCC 用 2 倍）。这背后有深刻的数学原理：

- **2 倍扩容**：简单粗暴。
  - *缺点*：会导致内存无法重用。比如你申请了 1, 2, 4, 8, 16... 当你需要申请 32 字节时，前面的 1+2+4+8+16 = 31 字节，加起来都凑不够 32。这会导致前面的内存碎片化。
- **1.5 倍扩容**：也就是按斐波那契数列增长（类似）。
  - *优点*：理论上，经过几次扩容后，前面释放掉的内存块之和能够容纳下一次申请的大小，有利于**内存复用**。

**vector扩容会导致迭代器和指针失效**

在 `vector` 中，迭代器（Iterator）本质上通常就是**裸指针 (`T\*`)** 的封装。

为什么会失效？

**扩容时（全局失效）**： 一旦触发 `reallocation`，旧内存被 `free` 了。之前指向旧内存的所有迭代器、指针、引用瞬间变成**野指针**。

~~~c++
vector<int> v = {1, 2, 3};
auto it = v.begin();
v.push_back(4); // 假设触发扩容
cout << *it;    // 💥 崩溃！it 指向的内存已经释放了
~~~

**入/删除时（局部失效）**： 即使不扩容，你在中间插入/删除元素，由于 `vector` 必须移动后续元素来填补空缺或腾出空间，**操作点之后**的所有迭代器都会失效。

~~~c++
std::vector<int> vec = {1, 2, 3, 4, 5};
auto it = vec.begin() + 2;
int val = *it;  // 保存值
vec.insert(vec.begin() + 1, 99);
// 此时 it 可能失效！
// std::cout << *it;  // 危险！
~~~

**`clear()`不释放内存**

~~~c++
vector<int> v(10000);
v.clear();
~~~

执行完 `clear()` 后：

- `size()` 变成了 0。
- `capacity()` 依然是 10000！ 内存还在手里攥着。
- 原因：为了避免你马上又要 `push_back` 导致重新分配。

那么如何强制释放内存？

C++11 前：`vector<int>().swap(v);` （用一个空 vector 和它交换，原来的大内存交给临时对象去析构）。

C++11 后：`v.shrink_to_fit();` （请求缩小容量以适配当前 size，但不保证一定执行）。

**`vector<bool>`存的是比特位**

为了节省空间，`vector<bool>` 实际上并没有存储 `bool`（1字节），而是存储了 **bit（位）**。它用 1 个 bit 代表一个 bool。

省空间：空间占用是普通的 1/8。

- 代价：
  - **没有地址**：你不能对里面的元素取地址 `&v[0]`，因为 CPU 无法寻址到 bit 级别（最小寻址单位是 Byte）。
  - **操作慢**：访问时需要进行位运算（移位、与、或）。
  - **非标准容器**：它甚至不完全符合 STL 容器的标准要求。
- 建议：如果你需要存布尔数组且不缺那点内存，用 `vector<char>` 或 `deque<bool>` 代替。

**vector的内存与析构**

1. **栈上**：`vector` 对象本身（也就是那 3 个指针：`start`, `finish`, `end_of_storage`）。
2. **堆上**：一大块连续的内存用来存数据。

但是，关于 **“一系列的 delete”** 这一点，需要做一个极其重要的**微调**。这涉及到 C++ 内存管理中 **“对象生命周期”** 和 **“原始内存分配”** 的分离。

我们要把 `vector` 的析构过程拆解为两个独立的步骤：

第一步：清理对象的析构

如果 `vector` 里存的是对象（比如 `vector<Hero>`），析构函数确实需要遍历每一个活着的元素。

- 动作：它会从 `_Myfirst` 遍历到 `_Mylast`。
- 执行：对每一个元素调用它们**自己的析构函数** (`element.~Hero()`)。
- 目的：让每个元素有机会处理自己的后事（比如 `Hero` 自己可能申请了别的资源，要让它释放）。

第二步：释放内存

 `vector` 的数据在堆上是连续存储的。 当初申请的时候，是像 `malloc(100 * sizeof(Hero))` 这样一次性申请的一大块。

- 动作：调用分配器（Allocator）的 `deallocate` 方法。
- 执行：把 `_Myfirst` 指向的那**整块**大内存，一次性还给操作系统。
- 目的：释放堆内存。

~~~c++
~vector() {
    // 步骤 1：手动调用每个元素的析构函数 (Loop)
    // 就像这里有一排房间，拆房子前先把里面的人请出去
    for (auto p = _Myfirst; p != _Mylast; ++p) {
        p->~string(); // 调用 string 的析构（释放 string 自己管理的堆内存）
    }

    // 步骤 2：释放 vector 拥有的这块地皮 (One-shot)
    // 只有一次！因为当初是一次性批下来的地。
    // 相当于 delete[] _Myfirst; 
    allocator.deallocate(_Myfirst, capacity); 
}
~~~

如果vector 存的是**裸指针**，比如 `vector<Hero*> v`：

1. 步骤 1：它遍历指针，调用指针的析构函数。但**指针是内置类型，没有析构函数**（啥都不干）。
2. 步骤 2：它释放存指针的那块堆内存。

**后果**：指针指向的那些 `Hero` 对象**没人管了！** —— **内存泄漏**。

**正确做法**：

- 要么在 vector 析构前，手动循环遍历 `delete v[i]`。
- 要么（强烈推荐）存智能指针：`vector<unique_ptr<Hero>>`。这样步骤 1 里调用 `unique_ptr` 的析构函数时，就会自动 delete 对应的 Hero。

| **维度**     | **评价**     | **备注**                    |
| ------------ | ------------ | --------------------------- |
| **随机访问** | ⭐⭐⭐⭐⭐ (极快) | 指针直接偏移                |
| **尾部插入** | ⭐⭐⭐⭐⭐ (极快) | 摊销 $O(1)$                 |
| **中间插入** | ⭐ (极慢)     | 需要移动后续所有数据 $O(N)$ |
| **内存利用** | ⭐⭐⭐ (中等)   | 有 `capacity` 预留空间浪费  |
| **缓存友好** | ⭐⭐⭐⭐⭐ (极佳) | 连续内存，Cache Hit 率最高  |

## Deque

### Deque的构成

**表面上看它是连续的（支持 `[]` 随机访问），实际上它是分段的。**

`vector` 只有一块大内存。`deque` 则由两部分组成：

**缓冲区 (Buffers / Nodes)**

这是实际存数据的地方。 `deque` 会申请许多段**固定大小**（例如 512 字节）的小内存块。每一块都像是一个小的 static array。

**中控器 (The Map)**

既然数据是分散的，怎么让用户感觉它们在一起呢？这就需要一个“目录”。 `deque` 内部维护了一块连续的内存（其实就是一个 `T**` 指针数组），我们称之为 **Map**（注意别和 `std::map` 搞混，这里指的是映射表）。

- Map 的每个元素：都是一个指针，指向一个缓冲区。
- 逻辑连续：只要 Map 里的指针是连续排列的，我们就可以通过计算找到数据。

### Deque的迭代器

这是 `deque` 的灵魂。 在 `vector` 中，迭代器就是个裸指针。但在 `deque` 中，迭代器必须是一个**类 (Class)**，因为它要负责“欺骗”用户，让用户觉得内存是连续的。

为了实现这一点，`deque` 的迭代器内部维护了 **4 个指针**：

~~~c++
struct __deque_iterator {
    T* cur;    // 1. 指向当前缓冲区的当前元素
    T* first;  // 2. 指向当前缓冲区的头部
    T* last;   // 3. 指向当前缓冲区的尾部
    T** node;  // 4. 指向中控器(Map)中指向当前缓冲区的那个位置
};
~~~

**迭代器如何工作？**

当你执行 `it++` 时：

1. 先 `cur++`。
2. 检查 `cur == last` ?
   - 如果没到边界，操作结束。
   - 如果到了边界（当前缓冲区走完了）：
     - `node++` （在中控器里跳到下一个缓冲区）。
     - `first = *node` （拿到新缓冲区的头）。
     - `last = *node + buffer_size` （拿到新缓冲区的尾）。
     - `cur = first` （指向新数据的开始）。

这就是为什么 `deque` 的遍历比 `vector` 慢的原因：**每次 `++` 都要进行一次边界检查，跨区时还要进行复杂的指针切换。**

### Deque的扩容

`vector` 只能向后扩容，向前扩容需要移动所有数据（$O(N)$）。 `deque` 为什么头尾插入都是 $O(1)$？

**尾部插入 (`push_back`)**

1. 看最后一个缓冲区满没满？

2. 如果没满，直接插。

3. 如果满了：

   - 申请一个新的 缓冲区。

   - 在 Map 的后方追加一个指向新缓冲区的指针。

   - 把数据放进新缓冲区。

   - 重点： 原来的数据完全不用动！ 

如果当前块有空间：直接插入（O(1)）

如果当前块已满：分配新块（O(1) 分配 + 可能更新映射表）

所以尾部插入的时间复杂度是**O(1) **。

**头部插入 (`push_front`)**

1. 看第一个缓冲区前面还有没有空位？
2. 如果有，直接插。
3. 如果没有：
   - 申请一个新的 **缓冲区**。
   - 在 **Map** 的前方追加一个指向新缓冲区的指针。
   - 把数据放进新缓冲区。
   - 重点： 后面的数据也完全不用动！

如果第一个块有空间：直接插入（O(1)）

如果第一个块已满：分配新块（O(1) 分配 + 可能更新映射表）

所以头部插入的时间复杂度也是**O(1)**。

**中间插入(`insert`)**

和vector一样需要移动数据，但可能跨块移动，不止在一个块内移动，所以时间复杂度是O(n)。

**Map满了后**

中控器 Map 本身也是块连续内存（指针数组），它满了怎么办？

：Map 也会扩容。

1. 申请一块更大的 Map（通常 2 倍）。
2. 把旧 Map 里的**指针**拷贝过去（拷贝指针很快，因为不涉及拷贝实际的大对象）。
3. 让 `deque` 使用新 Map。

这比 `vector` 的扩容轻量得多，因为**实际存储数据的那些缓冲区完全不需要移动**，只需要重排一下目录（Map）即可。

但是因为要移动指针所以时间复杂度应该也是**O(n)**。

### deque的随机访问

`vector` 的 `v[i]` 极其简单：`*(start + i)`。 `deque` 的 `d[i]` 就要做数学题了。

假设缓冲区大小是 `N`。我们要访问逻辑下标 `i`。

1. **它在哪一段？** `row = i / N` （在 Map 的第几号指针里）
2. **它在那一段的哪里？** `col = i % N` （在缓冲区的偏移量）
3. **计算地址**： `*(*(map + row) + col)`

这就是为什么 `deque` 虽然支持随机访问，但速度比 `vector` 慢（涉及除法和取模指令，以及两次解引用）。

### deque的内存

假设你存一个 `deque<int>`，即使里面只有一个整数：

1. **对象本身**：
   - `start` 迭代器（4 个指针）
   - `finish` 迭代器（4 个指针）
   - Map 指针（1 个指针）
   - Map 大小记录（1 个整数）
   - **合计**：栈上对象就要占用约 80 字节（64位系统）！相比之下 `vector` 只要 24 字节。
2. **堆内存**：
   - 至少要分配一个 Map。
   - 至少要分配一个缓冲区（哪怕只存 1 个 int，也要申请 512 字节）。

**结论**：`deque` 对**小数据量**及其**不友好**，内存浪费严重。

| **特性**       | **评价**     | **原因**                                                     |
| -------------- | ------------ | ------------------------------------------------------------ |
| **随机访问**   | ⭐⭐⭐ (良)     | 需要做除法和两次寻址                                         |
| **头部插入**   | ⭐⭐⭐⭐⭐ (极快) | 仅分配新块，不移动旧数据                                     |
| **尾部插入**   | ⭐⭐⭐⭐⭐ (极快) | 同上                                                         |
| **中间插入**   | ⭐⭐ (较慢)    | 虽然是分段的，但中间插依然要推挤元素                         |
| **内存开销**   | ⭐ (大)       | 迭代器大、Map 占用、缓冲区碎片                               |
| **迭代器失效** | ⭐⭐⭐⭐ (稳)    | 只要不删中间元素，扩容时指针不失效（因为数据没搬家），但迭代器状态可能失效。 |

当需要**在两端**频繁增删数据时（比如实现一个任务队列）。

当元素**非常大**（几兆一个），此时 `vector` 扩容时的搬迁成本太高，`deque` 是很好的替代品。

这就是为什么 `std::stack` 和 `std::queue` 默认基于 `deque` 实现的原因：**扩容平滑，没有剧烈的内存抖动。**

### deque与Cache未命中

**`std::vector` 的表现（顺滑）**：

- 它是连续内存。CPU 的**硬件预取器 (Hardware Prefetcher)** 非常聪明。
- 当你读取 `v[0]` 时，CPU 预判你可能会读 `v[1]`, `v[2]`... 所以它会自动把后续的一整块内存预加载到 L1 Cache 里。
- **结果**：你遍历 vector 时，几乎都是在 Cache 里拿数据，速度飞快。

**`std::deque` 的表现（颠簸）**：

- 假设你正在遍历 Buffer A 的最后一个元素。CPU 兴致勃勃地预取了 Buffer A 后面的一块内存。
- **突然！** 你的迭代器 `++` 了，跨越了边界。
- **逻辑跳转**：程序必须回到 Map（页目录），读取下一个指针，然后跳转到 Buffer B（这个 Buffer B 在堆内存的物理地址可能和 Buffer A 相隔十万八千里）。
- **预取失效**：CPU 刚才预取的 Buffer A 后面的数据全是废的。
- **Cache Miss**：CPU 必须停下来，去主存（RAM）里把 Buffer B 的数据搬进 Cache。
- **TLB Miss**：如果 Buffer B 所在的内存页不在 TLB 快表里，CPU 还要走一遍操作系统的页表查找流程。

## list

### list的构成

`std::list` 本质上是一个 **双向循环链表**。

~~~c++
struct __list_node {
    __list_node* prev;  // 指向前一个节点 (8字节)
    __list_node* next;  // 指向后一个节点 (8字节)
    T data;             // 数据本身
};
~~~

假设你存一个 `int` (4字节)。

- 在 64 位系统下，两个指针就要占 16 字节。
- 额外成本高达 400%！ (16 / 4)。
- 相比之下，`vector` 几乎没有任何额外开销（摊销后）。
- 结论：如果元素很小（比如 `int`, `bool`, `char`），千万别用 `list`。

### list的稳定性

在 `vector` 和 `deque` 中，插入或扩容会导致迭代器失效（变成野指针）。 但在 `list` 中： **除了你显式删除的那个节点，其他任何迭代器永远不会失效。**

- 原理：因为每个节点在内存里的位置是固定的，插入新节点只是改改指针指向，不会搬迁旧节点。
- 场景：如果你需要在遍历的过程中删除元素，或者保存指向某个元素的指针并在很久以后使用，`list` 是唯一的选择。

### list与缓存未命中

由于节点是随机分配的，节点 A 可能在堆的开头，节点 B 可能在堆的结尾。 **没有任何空间局部性。** 硬件预取器面对 `list` 完全没辙，只能眼睁睁看着 CPU 一次次停顿等待主存数据。

**结论**：在遍历速度上，`list` 通常比 `vector` 慢 10 倍到 50 倍（取决于数据量）。

### list的数据转移是O(1)

list可以完成一个 vector做梦都做不到的操作：$O(1)$ 的数据转移。

假设你有两个链表 `list1` 和 `list2`。你想把 `list2` 里的一段数据剪切到 `list1` 里。

- **`vector` 的做法**：
  1. 在 `vector1` 开辟新空间。
  2. 把数据从 `vector2` **拷贝** 过去。
  3. 把 `vector2` 里的旧数据析构、删除。
  4. 如果是对象，这涉及大量的构造和析构。
- **`list` 的做法 (`splice`)**：
  1. 找到那串节点的头和尾。
  2. **断开** `list2` 的指针。
  3. **连上** `list1` 的指针。
  4. **完成！** 数据对象本身在内存里一动没动，只是连接变了。

### std::forward_list

为了节省空间从两个指针变为一个指针

只有 `next` 指针，没有 `prev`。

内存：省了一个指针（8 字节）。

代价：

- 只能向后遍历。
- 没有 `size()` 方法！ （为了保证 $O(1)$ 且不存储额外的大小计数器，极致省内存）。
- 没有 `push_back`！ （因为找不到尾巴，要遍历到最后才能插，是 $O(N)$，所以干脆不给）。只能 `push_front`。

| **维度**          | **评价**     | **原因**                      |
| ----------------- | ------------ | ----------------------------- |
| **随机访问**      | ❌ (不支持)   | 只能顺藤摸瓜 $O(N)$           |
| **任意位置插入**  | ⭐⭐⭐⭐⭐ (极快) | 只要有迭代器，就是 $O(1)$     |
| **拼接 (Splice)** | ⭐⭐⭐⭐⭐ (神技) | 唯一也是最大的优势，指针交换  |
| **内存开销**      | ⭐ (极大)     | 每个节点额外 16 字节 + 碎片化 |
| **缓存友好**      | ⭐ (极差)     | 典型的“指针追逐”，CPU 噩梦    |
| **迭代器失效**    | ⭐⭐⭐⭐⭐ (最稳) | 除非删除该节点，否则永不失效  |

除非你需要 **大量的、频繁的在序列中间插入/删除**，或者需要 **$O(1)$ 的 splice 操作**。

否则，**永远优先考虑 `vector`**。哪怕是在中间删除，对于小对象来说，`vector` 的 `memmove`（内存搬移）往往比 `list` 的指针操作加 Cache Miss 还要快。

## array

C++11 引入的，用来彻底取代 C 风格数组 `int arr[10]`。

`std::array<int, 100>` 的内部很简单：

~~~c++
template<typename T, size_t N>
struct array {
    T _Elems[N]; // 就是一个裸数组！
    
    // ... 一些简单的函数封装 ...
};
~~~

**没有指针**：它不存 `begin`, `end`, `capacity` 指针。因为大小 `N` 是**编译期常量**，写在模板参数里的。

**存储位置**：

- 如果你在函数里写 `std::array<int, 100> a;`，这 400 字节**全部在栈上**。
- 这和 `vector`（对象在栈，数据在堆）完全不同。

**速度快**

**零堆分配**：没有 `new`，没有 `delete`，没有系统调用。它是随着栈帧的分配瞬间诞生的。

**绝对连续**：它就是一块纯粹的内存，Cache Hit 率极高。

**编译器优化**：因为长度 `N` 固定，编译器可以把循环展开，甚至把整个数组直接优化进寄存器。

**可能栈溢出**

因为栈空间很有限（通常只有几 MB）。 如果你写 `std::array<int, 1000000>`（4MB），大概率会直接把栈撑爆，程序崩溃。 **经验**：大数组用 `vector`，小数组（几十几百个元素）用 `array`。

# 关联容器

什么是关联：数据的位置不是由你决定的（像 `vector` 那样），而是由数据本身（Key）的大小决定的。

关联式容器包括：`std::set`（集合）、`std::map`（映射），以及它们允许重复的版本 `multiset`/`multimap`。

## 关联式容器的底层：红黑树

为什么不用简单的二叉查找树（BST）？因为 BST 在极端情况下（比如按 1, 2, 3, 4, 5 顺序插入）会退化成一个链表，查找变成 $O(N)$。 为了保证 **$O(\log N)$** 的绝对查找效率，STL 选择了红黑树这种 **自平衡二叉查找树**。

**为什么不是AVL树？**

AVL 树：追求极致的平衡（左右高度差不超过 1）。查找极快，但插入删除时需要频繁旋转来调整平衡。

红黑树：追求“大致”的平衡（最长路径不超过最短路径的 2 倍）。

- 妥协的艺术：它的旋转次数少于 AVL，插入和删除的效率更高。
- 对于通用的 STL 库来说，红黑树是在 查找速度 和 修改速度 之间找到的最佳平衡点。

## 组成

一个典型的红黑树节点 (`_Rb_tree_node`) 在内存中包含：

1. **`_Parent`**：指向父节点的指针 (8 字节) —— 为了支持迭代器 `++` / `--` 回溯。
2. **`_Left`**：指向左孩子的指针 (8 字节)。
3. **`_Right`**：指向右孩子的指针 (8 字节)。
4. **`_Color`**：记录颜色（红/黑）(通常是一个 enum，占 4 字节或更少，甚至压缩到指针的低位)。
5. **`_Value`**：实际存储的数据 (`pair<const Key, T>` 或 `Key`)。

**隐形开销**： 存一个 `int`，至少要附带 **3 个指针 (24 字节)** + 颜色信息。 这比 `list` 还浪费内存！所以，**千万不要用 `map` 来存大量的小数据**（除非你必须依赖它的排序特性）。

## std::map与std::set

层都调用了同一个 `_Rb_tree` 模板类。唯一的区别在于**“载荷”**不同。

`td::set<K>`

- **节点内容**：只有 `Key`。
- **特点**：Key 就是 Value。Key 不能被修改。
- **迭代器**：`set` 的迭代器是 `const_iterator`。你不能通过迭代器修改元素，因为这会破坏树的排序。如果你想改，只能先删 (`erase`) 再插 (`insert`)。

`std::map<K, V>`

- **节点内容**：`std::pair<const K, V>`。

- **隐形陷阱**：**Key 是 `const` 的！**

  ```c++
  map<int, string> m;
  auto it = m.begin();
  it->first = 10;  // ❌ 编译错误！Key 不可变
  it->second = "Hi"; // ✅ Value 可以变
  ```

## []与at()和find()

~~~c++
map<string, int> scores;
int s = scores["Alice"];
~~~

1. 在树中查找 "Alice"。
2. 如果有：返回对应的 Value 的引用。
3. 如果**没有**：
   - 创建一个新节点，Key 是 "Alice"。
   - Value 使用默认构造函数初始化（对于 `int` 就是 0）。
   - 把这个新节点插入树中。
   - 返回 0 的引用。

**后果**：如果你只是想检查 "Alice" 在不在，却用了 `if (scores["Alice"] > 0)`，你会**意外地**往 map 里插入各种垃圾数据（0 值）。

**所以要使用安全的at()和find()**

**`scores.at("Alice")`**：如果没找到，抛出 `std::out_of_range` 异常。不会偷偷插入。

**`scores.find("Alice")`**：返回迭代器。如果没找到，等于 `end()`。**这是查询存在的标准写法。**

## 稳定性质

和 `list` 一样，`map/set` 是节点式存储。 **插入操作**绝对不会让现有迭代器失效。 **删除操作**只会让指向被删除那个节点的迭代器失效。

## cache命中率

红黑树的节点在堆上也是“满天星”分布的。 当你遍历 `map` 时（中序遍历），虽然逻辑上是 1, 2, 3, 4 有序的，但物理上：

- 节点 1 可能在地址 0x1000
- 节点 2 可能在地址 0x9000
- 节点 3 可能在地址 0x2000 **指针乱跳**严重，Cache Miss 率很高。

## 效率优化

如果我在 `map` 里插入数据的顺序本来就是有序的（比如 1, 2, 3, 4... 10000），效率会怎样？

- **直觉**：树会一直往右边长，还要不停旋转平衡，应该很慢？
- **真相**：STL 的 `insert` 函数有一个**重载版本** `insert(iterator hint, const value_type& val)`。
  - 如果你能给它一个“提示位置”（比如上一次插入位置的后面），STL 会先检查这个位置对不对。
  - 如果对，它就**直接在 $O(1)$ 时间内挂上去**（且不需要旋转）。
  - 所以，如果你知道数据有序，配合 `hint` 参数，`map` 的插入可以飞快。

## map和set总结

| **维度**      | **评价**     | **原因**                   |
| ------------- | ------------ | -------------------------- |
| **查找速度**  | ⭐⭐⭐⭐ (快)    | $O(\log N)$ 二分查找逻辑   |
| **插入/删除** | ⭐⭐⭐⭐ (快)    | $O(\log N)$ 只需要局部旋转 |
| **遍历速度**  | ⭐⭐ (慢)      | 节点分散，指针跳转多       |
| **内存开销**  | ⭐ (大)       | 3个指针 + 1个颜色/节点     |
| **有序性**    | ⭐⭐⭐⭐⭐ (完美) | 始终保持有序               |

## multimap和multiset

它们的底层还是_Rb_tree

### 插入逻辑

**`std::map / std::set` (Unique)**：

- 插入时，从根节点往下找。
- 如果发现 Key 已经存在：**立即停止，插入失败，返回已存在的那个节点的迭代器。**

**`std::multimap / std::multiset` (Multi)**：

- 插入时，从根节点往下找。
- 如果发现 Key 已经存在：**继续往树的深处走！**
- 它会将新节点插入到现有相同 Key 节点的**旁边**（通常是右子树的最左侧，或者依据实现而定）。
- **结果**：树中会存在多个 Key 相同的节点，它们在中序遍历（In-order Traversal）时会**紧挨在一起**。

### multimap没有[]

~~~c++
std::map<string, int> m;
m["Apple"] = 10; // ✅ 没问题

std::multimap<string, int> mm;
mm.insert({"Apple", 10});
mm.insert({"Apple", 20});

// ❌ 编译报错！multimap 没有 operator[]
// mm["Apple"] = 30;
~~~

`operator[]` 的语义是：**“寻找 Key 对应的那个 Value，如果没找到就创建一个。”** 但在 `multimap` 中，"Apple" 可能对应着 `10`，也可能对应着 `20`。

- `mm["Apple"]` 到底应该返回 `10` 还是 `20`？
- 有歧义。
- 所以 STL 设计者直接**砍掉了** `multimap` 的 `operator[]` 和 `at()` 函数。

**结论**：想往 `multimap` 里插数据，只能用 `insert()`。

### 查找

在 `unique` 的容器里，`find` 就够了。但在 `multi` 容器里，查找变得复杂了。

`multimap` 里有 5 个 "Apple"。

`find(key)`

- **行为**：返回指向**第一个** "Apple" 的迭代器。
- **用途**：只能告诉你“有没有”。

`count(key)`

- **行为**：返回 "Apple" 的个数（5）。
- **性能陷阱**：为了数数，它必须遍历这 5 个节点。如果重复元素极多（比如几万个），`count` 的复杂度是 $O(\log N + \text{count})$，可能会比较慢。

### equal_range(key)

~~~c++
auto range = mm.equal_range("Apple");

// 遍历所有的 "Apple"
for (auto it = range.first; it != range.second; ++it) {
    cout << it->second << " "; // 输出 10, 20...
}
~~~

**底层原理**：它在红黑树上进行了两次二分查找（分别找 Lower Bound 和 Upper Bound），效率极高。

### erase

~~~c++
std::multimap<string, int> mm;
mm.insert({"Apple", 1});
mm.insert({"Apple", 2});

// 写法 A：按 Key 删除
mm.erase("Apple"); 
// 💥 后果：所有的 "Apple" 全都被删光了！(返回删除个数 2)

// 写法 B：按迭代器删除
auto it = mm.find("Apple"); // 找到第一个
mm.erase(it); 
// ✅ 后果：只删除了第一个 "Apple"，其他的还在。
~~~

| **特性**         | **map / set**  | **multimap / multiset**       |
| ---------------- | -------------- | ----------------------------- |
| **重复 Key**     | ❌ 覆盖或失败   | ✅ 允许共存                    |
| **`operator[]`** | ✅ 支持         | ❌ **不支持**                  |
| **查找方式**     | `find`         | 推荐 `equal_range`            |
| **删除 Key**     | 删 1 个        | **删所有**                    |
| **典型场景**     | 身份证号 -> 人 | 成绩 -> 学生列表 (多个人同分) |

# 无序容器

C++11 引入了无序容器家族：

- `std::unordered_map` / `std::unordered_multimap`
- `std::unordered_set` / `std::unordered_multiset`

它们放弃了顺序，只追求一个目标：**$O(1)$ 的查找速度**。

它的底层核心：**开链哈希表**。

## 底层

`std::unordered_map` 的内存布局其实是一个 **“数组 + 链表”** 的组合体。

**骨架：桶数组** 

容器内部维护了一个 `std::vector`（或者类似动态数组）的结构。

- 这个数组的每一个位置，被称为一个 **“桶”**。
- 桶里存的不是数据本身，而是一个**指针**（或者迭代器），指向一个链表的头节点。

**血肉：节点链**    

实际的数据（Key-Value Pair）存放在堆上分配的独立节点中。

- 当两个不同的 Key 计算出相同的 Hash 值（哈希冲突）时，它们会被挂在同一个桶的链表下面。
- **注意**：为了节省内存，标准库通常使用 **单向链表 (Singly Linked List)** 来实现桶内结构（比 `std::list` 少一个指针）。

## 运作机制

当你执行 `map["Apple"] = 10;` 时，发生了什么？

1. **计算哈希 (Hash)**： 调用 `std::hash<string>` 函数，把 "Apple" 转换成一个巨大的整数（比如 `982348123`）。
2. **映射桶索引 (Map to Index)**： 用这个整数对桶的数量取模：`Index = HashValue % BucketCount`。假设桶数量是 10，结果就是 3。
3. **查找与插入**：
   - 跳到第 3 号桶。
   - 遍历这个桶挂着的链表。
   - 如果发现 Key 也是 "Apple"（用 `operator==` 比较），就更新 Value。
   - 如果走到链表尽头没发现，就 `new` 一个新节点，挂在链表头部（或尾部）

## 哈希表扩容

`vector` 满了要扩容，哈希表“挤”了也要扩容。这个过程叫 **Rehash**。

**负载因子 (Load Factor)**

STL 维护了一个指标：`load_factor() = 元素总数 / 桶的总数`。

- 默认的最大负载因子 (`max_load_factor`) 是 **1.0**。
- 这意味着：平均每个桶里挂 1 个元素时，它就觉得挤了，需要扩容。

**扩容过程 (极度昂贵)**

1. **分配新桶**：申请一个新的、更大的桶数组（通常是质数大小，或者是 2 倍，取决于编译器实现）。
2. **全员搬家**：
   - 这不像 `vector` 只要拷贝内存。
   - 它必须遍历旧表中的**每一个元素**。
   - **重新计算 Hash 值**（因为桶数量变了，`% BucketCount` 的结果也变了）。
   - 把元素挂到新表的正确位置。
3. **释放旧桶**。

**高手经验**： 如果你知道大概要存 100 万个数据，**务必** 提前调用 `reserve(1000000)`。 否则，从 0 扩容到 100 万，中间会发生多次 Rehash，CPU 都在忙着算哈希和搬节点，性能会极其惨烈。

## 哈希退化

问题：如果运气极差，或者被黑客攻击（Hash Flooding Attack），使得插入的 10000 个 Key，计算出来的 Hash 值全部一样（或者 `% BucketCount` 结果一样），会发生什么？

后果：

- 所有数据都挤在**同一个桶**里。
- 哈希表退化成了一个 **单向链表**。
- 查找复杂度从 $O(1)$ 瞬间崩塌为 **$O(N)$**。

防御：现代编译器（如 GCC, Clang）通常会在哈希函数中加入 随机种子 (Random Seed)。每次程序启动，哈希规则都不一样，让攻击者无法预测 Hash 值。

### Rehash失效情况

这一点 `unordered_map` 和 `vector` 很像，但又有点区别。

- **插入 (Insert)**：
  - 如果**没触发 Rehash**：迭代器**不失效**，指针**不失效**。（只是链表挂了个新节点，旧节点位置没动）。
  - 如果**触发了 Rehash**：**所有迭代器全部失效！**（因为桶数组换了，迭代器通常依赖桶数组）。但有趣的是，**指向元素的引用/指针通常不失效**（因为节点本身没重新 `malloc`，只是换了个桶挂着）。
- **删除 (Erase)**：
  - 只让指向被删除元素的迭代器失效。

**真实的 Rehash 过程：**

当 `unordered_map` 决定从 `N` 个桶扩容到 `2N` 个桶时，它必须做以下动作：

1. **分配**：申请 `2N` 个新的空桶（指针数组）。
2. **遍历**：它必须遍历旧表中链表上的**每一个节点**（一共 $N$ 个）。
3. **重算**：对于每个节点，重新计算 `HashValue % NewBucketCount`。（*注：虽然节点的 HashValue 通常会缓存下来不用重算，但模运算 `%` 必须重做*）。
4. **搬运**：把节点从旧链表上摘下来，挂到新表的对应位置。
5. **释放**：释放旧的桶数组。

时间复杂度应该是**O(n)**。

### 同key堆积情况

虽然 Key 不同了（比如一个是 "Apple"，一个是 "Azure"），但如果你的运势极差，或者哈希函数写得很烂，可能会发生**“不同 Key，同 Index”** 的惨剧。

假设你的哈希表有 10 个桶。

你插入了 10 个不同的字符串："A", "B", "C", ... "J"。

- **理想情况 (Good Hash)**：
  - "A" -> 桶 1
  - "B" -> 桶 5
  - "C" -> 桶 9
  - ...
  - **结果**：每个桶里 1 个元素。查找速度 **$O(1)$**。
- **糟糕情况 (Bad Hash / Collision)**：
  - 假设哈希函数算出来，这 10 个字符串模 10 后的结果**全是 3**。
  - **结果**：
    - **第 3 号桶**：挂着一个长度为 10 的链表（存着 A 到 J）。
    - **其他 9 个桶**：全空！
  - **性能**：查找 "J" 变成了 **$O(10)$**，也就是 **$O(N)$**。

**这和 `multimap` 的区别在哪？**

- **`multimap`**：这种拥堵是 **“天灾”**（逻辑强制的）。只要 Key 相同，神仙也救不了，Rehash 也没用（怎么扩容它们都要在一起）。
- **`unordered_map`**：这种拥堵是 **“人祸”**（哈希函数不好）。可以通过 **Rehash**（扩容桶数量）或者 **更换哈希函数** 来解决。
  - 例如：当桶从 10 扩容到 20 时，"A" 和 "B" 可能原来都在桶 3，但现在 "A" 去了桶 3，"B" 去了桶 13。**它们被打散了！**

因为 STL 默认的 `std::hash` 算法（通常是 MurmurHash, CityHash 或类似变体）设计得非常精妙，它具有 **雪崩效应 (Avalanche Effect)**：

> 输入的字符串哪怕只变动一个比特，输出的 Hash 值都会发生剧烈变化。

所以准确来说哈希表的查找应该是O(1+k)时间复杂度的。

## 内存开销

`unordered_map` 是典型的 **“空间换时间”**。

1. **桶数组**：哪怕是空的，也要占空间。默认可能会预分配一些桶。
2. **节点开销**：
   - Key + Value。
   - `next` 指针 (8字节)。
   - **Cached Hash Code (隐形开销)**：很多实现会在节点里额外存一个 `size_t` 的哈希值（8字节）。为什么？为了在 Rehash 或者比较时，不用每次都重算 Hash 函数（特别是对于 string 这种 Hash 很难算的 Key）。

| **维度**     | **std::map (红黑树)**            | **std::unordered_map (哈希表)**     |
| ------------ | -------------------------------- | ----------------------------------- |
| **查找速度** | 稳定 $O(\log N)$                 | 平均 $O(1)$，最差 $O(N)$            |
| **内存开销** | 高 (3指针/节点)                  | 极高 (桶数组 + 指针 + 缓存Hash)     |
| **有序性**   | ✅ 有序 (Key 排序)                | ❌ 无序 (乱糟糟)                     |
| **范围查找** | ✅ 支持 (`lower_bound`)           | ❌ 不支持 (没有逻辑相邻)             |
| **适用场景** | 需要按顺序遍历，或对最差性能敏感 | 只需要 Key-Value 映射，追求极致速度 |

# 容器适配器

## stack

`std::stack` (后进先出 LIFO)

- **默认底层**：`std::deque`。
  - *为什么不是 `vector`？* 因为 `stack` 不需要随机访问，只需要栈顶操作。`vector` 扩容时搬迁成本太高，而 `deque` 扩容平滑。
  - *为什么不是 `list`？* 内存碎片太多，慢。
- **可以换底层**：`std::stack<int, std::vector<int>> s;` （也是合法的）。

`stack` 对象内部只包含一个成员变量：`Container c;`。 所以它的内存分布、扩容机制，完全取决于你选的那个底层容器。

### 栈的pop()返回void

~~~c++
// 假设 pop() 返回 T
T t = s.pop();
~~~

如果 `pop` 已经把元素从栈里移除了，但在**拷贝**给 `t` 的过程中，拷贝构造函数抛出了异常。

**后果**：栈里的元素没了，`t` 也没接住。数据丢失！

**解决**：必须分开两步：先 `top()` 拿到引用，再 `pop()` 移除。

## queue

`std::queue` (先进先出 FIFO)

- **默认底层**：`std::deque`。
- **为什么不能用 `vector`？**
  - `queue` 需要在**头部**删除 (`pop_front`)。
  - `vector` 删除头部是 $O(N)$ 的（要移动后面所有人）。
  - 所以 `std::queue<int, std::vector<int>>` **编译会直接报错**（因为 `vector` 没有 `pop_front`）。

## priority_queue

它看起来像队列，实际上是 **堆 (Heap)**。 它保证 `top()` 永远是优先级最高（最大）的元素，查找 $O(1)$，插入删除 $O(\log N)$。

它通常使用 std::vector 作为底层容器。

虽然数据平铺在 vector 的连续内存里，但逻辑上它是一棵         完全二叉树。

**数组下标映射公式**（假设当前节点下标为 `i`）：

- **左孩子**：`2 * i + 1`
- **右孩子**：`2 * i + 2`
- **父节点**：`(i - 1) / 2`

### 堆的操作流程

假设是一个 **大顶堆 (Max Heap)**。

1. **插入 (`push`)**：
   - 先 `vector.push_back()` 把元素放到数组末尾（逻辑树的叶子）。
   - **上浮 (Sift Up / Percolate Up)**：和父节点比大小。如果比爸爸大，就交换。一直换到干不过爸爸或者变成根节点为止。
   - 时间复杂度：树的高度，即 $O(\log N)$。
2. **删除 (`pop`)**：
   - **不能直接删根节点！**（否则数组头没了，后面全要挪，而且树结构散了）。
   - **偷梁换柱**：把 **根节点** 和 **数组最后一个元素** 交换。
   - `vector.pop_back()` 删掉原来的根（现在的尾巴）。
   - **下沉 (Sift Down / Percolate Down)**：新的根节点（原来的小兵）太小了，压不住阵。让它和左右孩子里最大的那个换。一路换下去，直到平衡。
   - 时间复杂度：$O(\log N)$。

### 隐藏的算法

`priority_queue` 实际上是封装了 STL 的算法库：

- `push` 调用的其实是 `std::push_heap`。
- `pop` 调用的其实是 `std::pop_heap`。
- 构造时调用的其实是 `std::make_heap`。

### 是 Max Heap 还是 Min Heap？

默认是 `std::less<T>`，这意味着大的元素优先级高（大顶堆）。

如果你要小顶堆（小的先出，比如刷 LeetCode 合并 K 个链表），必须写全模板参数：

~~~c++
//              类型,  底层容器,        比较器
std::priority_queue<int, vector<int>, greater<int>> minHeap;
~~~

### 其它

 `priority_queue` 是树，为什么不用指针连起来的真实树（比如红黑树）？

为了**速度快**。

- **指针树**（如 `set`）：节点在堆内存里满天飞，每次跳指针都是 Cache Miss。
- **二叉堆**（`priority_queue`）：数据完全紧凑在 `vector` 里。父子节点的计算只是简单的位运算（`*2`, `/2`），而且大概率都在同一个 Cache Line 里。
- **结论**：在只需要“取最大值”而不需要“搜索任意值”的场景下，`priority_queue` 比 `set` 快几个数量级。

# 特殊容器

## bitset

在编译期确定大小，把 1 个 bool 压缩到 1 个 bit。

`std::bitset<N>` 在底层并不是存了一堆 `bool`，而是存了一个 **整数数组**（通常是 `unsigned long` 或 `unsigned long long`）。

假设 `unsigned long` 是 64 位（8字节）：

- 如果申请 `bitset<64>`，它底层只占用 **1 个整数**（8字节）。
- 如果申请 `bitset<65>`，它底层占用 **2 个整数**（16字节）。

~~~c++
template<size_t N>
class bitset {
    // 如果能整除，刚好 N/64 个元素；否则需要额外一个元素存储剩余位
    static constexpr size_t _WordsCount = (N + 63) / 64;  // 或者 N/64 + (N%64 != 0)
    unsigned long _Words[_WordsCount];
};
~~~

**快**

为什么 `bitset` 快？因为 CPU 的 ALU（算术逻辑单元）天生就是做位运算的。

- 常规容器：把两个 `vector<bool>` 做“或”运算，CPU 需要循环 N 次。
- Bitset：把两个 `bitset<64>` 做“或”运算，CPU 只需要 **1 条指令**（对底层的 `unsigned long` 做 `OR`）。
  - 性能提升：理论上是 `vector<bool>` 的 64 倍（在 64 位机器上）。

**大小必须固定**：`bitset<100>` 的 100 必须是**编译期常量**。不能根据运行时变量来创建 bitset。这是它和 `vector<bool>` 最大的区别。

**没有迭代器**：不能用 `for(auto b : bs)` 遍历它。只能用 `[]` 访问。

**栈溢出风险**：如果写 `bitset<10000000>`，直接在栈上开几 MB 的空间，程序可能会崩。大位图请用 `vector<bool>` 或第三方库（如 Boost.DynamicBitset）。

## string

`string` 本质上是 `std::vector<char>` **的特化魔改版**

对象本身（32 字节）：

- `ptr`（堆指针）
- `size`
- `capacity`
- **Union hack**：当 `size < 15` 时，这些成员变量的空间会被复用为一个 `char buffer[16]`，直接在栈上存字符。

**String隐藏了第N+1个字符**

这是 `string` 和 `vector<char>` 最本质的区别。

- `vector<char> v = {'H', 'i'};` —— 内存里只有 'H', 'i'。
- `string s = "Hi";` —— 内存里实际存的是 'H', 'i', **'\0'**。

**为什么？** 为了配合 `c_str()` 方法。 C++ 为了兼容古老的 C 语言接口（如 `printf`, `open`, `atoi`），必须保证字符串后面跟着一个 `\0`。 所以，`string` 的 `capacity` 实际上往往比看到的容量多预留一个字节给 `\0`，并且在每次修改操作后，都要维护这个结尾符号。

**string满了也要扩容**

~~~c++
string s;
s += "a"; // 可能导致 malloc
s += "b"; // 可能导致 free + malloc
~~~

- **切记**：做大量拼接前，务必调用 `s.reserve(total_len)`。

### string 是写时复制的吗？

**C++11 之前**：大部分实现（如 GCC）是 COW 的。`string s2 = s1` 只是增加引用计数，不拷贝内存。

**C++11 之后**：**禁止 COW**。因为 COW 在多线程下为了维护引用计数，需要原子操作，性能反而下降，且会导致迭代器失效规则极其复杂。现在的 `string` 都是实实在在的**深拷贝**（除非用 `move`）。

## valarray

`td::valarray<double>` 看起来像 `vector<double>`，但区别极大：

1. **没有迭代器**：起初设计时，它根本不想让你遍历。它希望把整个数组当成一个数来算。
2. 整体运算

~~~c++
valarray<int> v1 = {1, 2, 3};
valarray<int> v2 = {4, 5, 6};

// 这一行代码，底层可能触发 SIMD 指令
valarray<int> v3 = v1 * 2 + v2; 
// v3 变成 {6, 9, 12}，完全是数学向量的写法
~~~

### 切片与步长


~~~c++
// 假设 v 是一个 100 个元素的数组
// slice(start, count, stride)
// 从下标 0 开始，取 5 个元素，每次跳 3 步 (0, 3, 6, 12...)
auto my_slice = v[std::slice(0, 5, 3)];
~~~

# 迭代器

## 内存情况

很多人以为迭代器就是指针的“别名”。在 `vector` 里或许是，但在 `map` 和 `deque` 里，**迭代器是一个极其复杂的智能代理对象**。

虽然迭代器模仿了指针的行为（`*`, `->`, `++`, `--`），但在底层，它通常是一个 **类**。

**`vector<T>::iterator`**：

- **Release 模式**：通常就是 `T*`（裸指针）。大小 8 字节。
- **Debug 模式**：往往包含一个 `T*` 指向元素，还有一个 `Container*` 指向父容器（为了检查越界）。大小可能是 16 或 24 字节。

**`list<T>::iterator`**：

- 它是一个类，内部包装了一个 `Node*` 指针。
- **`operator++` 的实现**：`_Ptr = _Ptr->_Next;`
- **`operator\*` 的实现**：`return _Ptr->_Value;`

**`deque<T>::iterator`** (我们在 deque 章节见识过)：

- 它是一个巨无霸。内部有 **4 个指针** (`cur`, `first`, `last`, `node`)。
- 这是所有标准迭代器里最肥的。

**`map<K, V>::iterator`**：

- 它是一个类，内部包装了一个 `Node*`（红黑树节点指针）。
- **`operator++` **：它不是简单的指针移动，而是 **“寻找二叉搜索树的后继节点”** 的算法！
  - 如果有右子树，走右子树的最左节点。
  - 如果没有右子树，向上找父节点，直到找到一个父节点是“左孩子”为止。
- **代价**：`map` 的迭代器 `++` 操作虽然平均是 $O(1)$，但最坏情况（比如回溯到根）是 $O(\log N)$。

## Iterator Traits (类型萃取)

例如：`std::advance(it, n)` 这个函数，作用是把迭代器 `it` 向前移动 `n` 步。

- 如果是 `list`，它必须做 `n` 次循环 `++`（$O(n)$）。
- 如果是 `vector`，它应该直接 `it += n`（$O(1)$）。

编译器怎么知道 `it` 到底是哪种？它又不能用 `if (typeid(it) == vector_iterator)`（这是运行时 RTTI，太慢）。

**解决方案：Traits 技术 (编译期分发)**

每个迭代器类里，都必须定义一个 `typedef` 叫 `iterator_category`。

~~~c++
// vector 的迭代器里大概长这样
struct vector_iterator {
    using iterator_category = std::random_access_iterator_tag; // 身份证
    // ...
};

// list 的迭代器里大概长这样
struct list_iterator {
    using iterator_category = std::bidirectional_iterator_tag; // 身份证
    // ...
};
~~~

**STL 源码里的 `advance` 大概是这么写的（伪代码）：**

~~~c++
template <typename Iter>
void advance(Iter& it, int n) {
    // 1. 萃取：提取出这个迭代器的“身份证”
    using Category = typename std::iterator_traits<Iter>::iterator_category;
    
    // 2. 调度：调用重载的内部函数
    __advance(it, n, Category());
}

// 针对随机访问的重载版本（编译期决定调用这个）
void __advance(Iter& it, int n, random_access_iterator_tag) {
    it += n; // O(1) 操作
}

// 针对双向/前向的重载版本
void __advance(Iter& it, int n, bidirectional_iterator_tag) {
    while(n--) ++it; // O(N) 循环
}
~~~

这就是为什么 STL 如此高效。所有的判断都在 **编译期 (Compile-time)** 完成了。生成的机器码里没有任何 `if-else` 判断，直接就是最优指令。

## 迭代器的end()

`end()` 指向容器 **最后一个元素之后**的位置。

**vector**：`end()` 真的就是指向那块内存后的一个字节。

**List**：`end()` 指向那个 **哨兵节点 (Sentinel Node)**。

**Tree (Map/Set)**：`end()` 通常也指向一个特殊的哨兵节点（Header），它是根节点的父亲。

~~~c++
auto it = v.end();
std::cout << *it; // 💥 越界访问！UB (Undefined Behavior)
~~~

**为什么设计成左闭右开 `[begin, end)`？**

1. **空容器判断**：`begin() == end()` 极其自然。
2. **循环终止**：`it != end()` 不需要特殊处理最后一个元素。
3. **分治算法**：方便切分区间。

## 其它迭代器

**插入迭代器**

~~~c++
vector<int> v;
auto it = std::back_inserter(v);
*it = 10; // 这一步居然等价于 v.push_back(10) !
~~~

**流迭代器**

~~~c++
// 这一行代码会阻塞，等待你输入整数
std::istream_iterator<int> input_it(std::cin);
int val = *input_it; // 读入一个整数
++input_it;          // 准备读下一个
~~~

在 C++20 之前，总是传一对迭代器： `std::sort(v.begin(), v.end());`

C++20 引入了 **Ranges**，终于可以直接传容器了： `std::ranges::sort(v);`

# 算法

即学即用吧

# 函数对象

**函数对象**，在 C++ 中通常被称为 **仿函数**

## 形式

从语法上看，**任何重载了函数调用运算符 `operator()` 的类对象，都是函数对象。**

~~~c++
// 1. 定义一个类
struct Greeter {
    // 2. 重载 () 运算符
    void operator()(std::string name) {
        std::cout << "Hello, " << name << "!" << std::endl;
    }
};

int main() {
    Greeter g; 
    // 3. 像调用函数一样使用对象
    g("Gemini"); // 实际上调用的是 g.operator()("Gemini");
}
~~~

看起来是不是有点多此一举？为什么要搞个类，直接写个函数不香吗？

## 函数对象的状态

普通函数（包括函数指针）是无状态的。 如果你想让一个普通函数“记住”上一次调用时的值，你只能用全局变量或 `static` 变量（这会带来线程安全问题和代码耦合）。

**场景：找出大于 N 的数**

假设我们要用 `std::count_if` 统计 `vector` 里大于某个阈值的数。

普通函数写法

~~~c++
// 这里的 10 写死了！如果我想找大于 20 的，还得再写一个函数？
bool greaterThan10(int x) { return x > 10; } 

std::count_if(v.begin(), v.end(), greaterThan10);
~~~

函数对象

~~~c++
class GreaterThan {
    int threshold; // 【关键】内部状态：存阈值
public:
    GreaterThan(int t) : threshold(t) {} // 构造时传入

    bool operator()(int x) const {
        return x > threshold; // 使用内部状态
    }
};

// 使用：
std::count_if(v.begin(), v.end(), GreaterThan(10)); // 找大于 10
std::count_if(v.begin(), v.end(), GreaterThan(20)); // 找大于 20
~~~

## 优势

**为什么 STL 的 `std::sort` 往往比 C 语言的 `qsort` 快？**

- **C 语言的 `qsort`**：
  - 需要传入一个 **函数指针** `cmp`。
  - 编译器在编译 `qsort` 内部的代码时，它只知道“这里有个指针”，但不知道指针指向哪。
  - 所以，每次比较都必须通过指针进行 **间接调用 (Indirect Call)**。
  - **后果**：无法内联，且打断 CPU 流水线。
- **C++ 的 `std::sort` + 函数对象**：
  - `std::sort` 是模板。当你传入 `std::less<int>`（一个函数对象）时。
  - 编译器在编译阶段就知道：*“哦，你要调用的就是 `std::less::operator()`”*。
  - 编译器会直接把比较代码 **内联 (Inline)** 到排序循环里。
  - **后果**：没有函数调用开销，就像你自己手写了一个针对 `int` 的排序循环一样快。

## Lambda表达式

Lambda 允许在**原地**定义一个匿名的函数对象。

~~~c++
int threshold = 10;

// 写法：
std::count_if(v.begin(), v.end(), [threshold](int x) {
    return x > threshold;
});
~~~

~~~c++
// 编译器偷偷生成的类
class __Lambda_Generated_Name {
    int _threshold; // 对应捕获列表 [threshold]
public:
    __Lambda_Generated_Name(int t) : _threshold(t) {}
    
    bool operator()(int x) const { // 对应函数体
        return x > _threshold;
    }
};
~~~

**`[]` (Capture List)**：对应函数对象的**成员变量**（状态）。

**`()` (Parameter List)**：对应 `operator()` 的**参数**。

**`{}` (Body)**：对应 `operator()` 的**函数体**。

| **类型**               | **形式**              | **状态 (State)** | **内联优化**    | **推荐场景**                   |
| ---------------------- | --------------------- | ---------------- | --------------- | ------------------------------ |
| **普通函数**           | `void func(int)`      | ❌ 无             | ❌ 难 (指针调用) | 全局通用逻辑，无状态           |
| **函数指针**           | `void (*ptr)(int)`    | ❌ 无             | ❌ 难            | C 语言接口兼容                 |
| **函数对象 (Functor)** | `struct X { op() }`   | ✅ 有 (成员变量)  | ✅ 极佳          | 复杂状态逻辑，STL 算法         |
| **Lambda**             | `[x](int){...}`       | ✅ 有 (捕获列表)  | ✅ 极佳          | 局部短逻辑，STL 算法 (首选)    |
| **`std::function`**    | `function<void(int)>` | ✅ 有             | ❌ 差 (类型擦除) | 需要存储不同类型的 Callable 时 |

在编译器眼里，**根本不存在 Lambda 表达式这种东西**。Lambda 只是给程序员写的“语法糖”。

程序员写的lambda

~~~c++
int a = 10;
int b = 20;

// 捕获 a (值拷贝), b (值拷贝)
auto myLambda = [a, b](int x) {
    return a + b + x;
};

int res = myLambda(5);
~~~

编译器眼里的

~~~c++
// 1. 编译器自动生成一个类，名字通常是乱码，唯一的
class __Lambda_Compiler_Generated_Name_X123 {
private:
    // 【对应 [a, b]】
    // 捕获列表里的变量，变成了类的成员变量！
    int _a; 
    int _b;

public:
    // 2. 编译器自动生成构造函数
    // 用来初始化成员变量
    __Lambda_Compiler_Generated_Name_X123(int a_in, int b_in) 
        : _a(a_in), _b(b_in) {}

    // 3. 【对应 (int x) { ... }】
    // 函数体变成了 operator()
    // 注意：默认是 const 函数，除非你加了 mutable 关键字
    int operator()(int x) const {
        return _a + _b + x;
    }
};

// --- 回到 main 函数 ---

// 4. 你的 auto myLambda 其实是：
__Lambda_Compiler_Generated_Name_X123 myLambda(a, b); // 调用构造函数，把数据存进对象

// 5. 你的 myLambda(5) 其实是：
int res = myLambda.operator()(5);
~~~

| **Lambda 写法**    | **编译器生成的类**                             |
| ------------------ | ---------------------------------------------- |
| **`[`捕获列表`]`** | **成员变量** (Member Variables) + **构造函数** |
| **`(`参数列表`)`** | **`operator()` 的参数**                        |
| **`{`函数体`}`**   | **`operator()` 的代码体**                      |
| **`mutable`**      | 决定 `operator()` 是否是 `const` 的            |
| **`auto f = ...`** | 实例化这个临时类的对象                         |

Lambda 就是类对象，就能解释很多现象：

1. **为什么 Lambda 可以有状态？**

   - 因为它有成员变量（捕获的值）。

2. **为什么 `[=]`（按值捕获） 和 `[&]`（按引用捕获） 行为不同？**

   - `[=]`：生成的成员变量是 `int _a;`，构造时拷贝数值。
   - `[&]`：生成的成员变量是 `int& _a;`（引用类型），构造时存地址/引用。

3. **Lambda 的大小是多少？**

   - 如果空的 `[]`：大小通常是 1 字节（C++ 空类大小不能为 0）。
   - 如果捕获了 `[a, b]` (int)：大小就是 8 字节（2 个 int 成员）。
   - 它和普通对象一样，捕获越多，体积越大。

   ### lambda表达式申请堆内存的情况

**情况A：lambda对象本身被存在了堆上**

~~~c++
// 虽然语法有点怪，但这完全合法
// p_lam 指向堆上的一块内存，这块内存里存着捕获的变量
auto* p_lam = new auto([x](int a) { return x + a; });

// 调用时要解引用
(*p_lam)(5); 

// 别忘了释放
delete p_lam;
~~~

**栈**：指针 `p_lam` (8字节)。

**堆**：Lambda 对象本体（存着 `x=10`）。

**代码段**：`operator()` 函数指令。

**情况B：使用std::function**

~~~c++
// std::function 可能会触发堆分配！
std::function<int(int)> func = [x](int a) { return x + a; };
~~~

**原理**：`std::function` 内部通过 **类型擦除 (Type Erasure)** 来存储 Lambda 对象。

**小对象优化 (SSO)**：如果你的 Lambda 捕获的数据很少（比如只捕获一个 int），`std::function` 会把它直接存放在自己的栈内存里。

**大对象上堆**：如果你的 Lambda 捕获了**一大堆变量**（比如捕获了一个大结构体），超过了 `std::function` 的内部缓冲区，它就会默默地调用 `new`，把你的 Lambda 对象分配到 **堆上**。

**情况C：Lambda对象在栈上但持有堆内存**

~~~c++
// 我想在 Lambda 里用一个 vector，但不想拷贝它
auto lam = [v = std::vector<int>{1, 2, 3}]() {
    // 这里的 v 是 lambda 的成员变量
    std::cout << v.size(); 
};
~~~

**Lambda 对象 (`lam`)**：在 **栈** 上。

- 它内部有一个成员变量 `v`（`vector` 对象）。
- 这个 `v` 只有 24 字节（3个指针），存在栈上（嵌在 `lam` 肚子里）。

**真实数据**：`1, 2, 3` 这些数字。

- 它们存在 **堆** 上。
- 栈上的 `lam` 里的 `v` 指向堆上的数据。
